import os
import sys
import logging
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import numpy as np
from datetime import datetime, timedelta
import akshare as ak

from crawlers.stock_data_unified import StockDataCrawler, get_stock_news as get_stock_news_akshare
from models.sentiment_analysis import FinancialSentimentAnalyzer
from analysis.stock_sentiment_analysis import StockSentimentAnalyzer

st.set_page_config(
    page_title="è‚¡ç¥¨æƒ…ç»ªåˆ†æä¸è¶‹åŠ¿æ´å¯Ÿå·¥å…·",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

@st.cache_resource
def init_modules():
    stock_crawler = StockDataCrawler()
    sentiment_analyzer = FinancialSentimentAnalyzer()
    stock_sentiment_analyzer = StockSentimentAnalyzer()
    return stock_crawler, sentiment_analyzer, stock_sentiment_analyzer

stock_crawler, sentiment_analyzer, stock_sentiment_analyzer = init_modules()

# ========== æ¨¡å—äºŒï¼šAlpha ç­›é€‰é›·è¾¾ ==========

# ç›®æ ‡æ± ï¼šè¦†ç›–ä¸»è¦è¡Œä¸šé¾™å¤´
WATCHLIST = [
    "600519",  # è´µå·èŒ…å°
    "300750",  # å®å¾·æ—¶ä»£
    "002594",  # æ¯”äºšè¿ª
    "601318",  # ä¸­å›½å¹³å®‰
    "000858",  # äº”ç²®æ¶²
    "601888",  # ä¸­å›½ä¸­è½¦
    "000333"   # ç¾çš„é›†å›¢
]

@st.cache_data(ttl=300)
def run_alpha_screener():
    """
    Alpha ç­›é€‰é›·è¾¾ï¼šæ‰«æ WATCHLIST ä¸­çš„è‚¡ç¥¨ï¼Œè®¡ç®— Z-Score
    ç›®æ ‡ï¼š10ç§’å†…å®Œæˆæ‰«æï¼Œä¸è°ƒç”¨ DeepSeek
    """
    logger = logging.getLogger(__name__)
    logger.info(f"========== å¼€å§‹ Alpha ç­›é€‰é›·è¾¾æ‰«æ ==========")
    
    results = []
    
    for code in WATCHLIST:
        try:
            logger.info(f"æ‰«æè‚¡ç¥¨: {code}")
            
            # è·å–è‚¡ç¥¨æ•°æ®
            from crawlers.stock_data_unified import fetch_comprehensive_data
            data = fetch_comprehensive_data(code)
            
            if not data['success']:
                logger.warning(f"è‚¡ç¥¨ {code} æ•°æ®è·å–å¤±è´¥ï¼Œè·³è¿‡")
                continue
            
            # æ£€æŸ¥ä»·æ ¼æ•°æ®æ˜¯å¦å……è¶³
            price_df = data['price_data']
            if price_df.empty or len(price_df) < 10:
                logger.warning(f"è‚¡ç¥¨ {code} ä»·æ ¼æ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
                continue
            
            # æ£€æŸ¥æ–°é—»æ•°æ®æ˜¯å¦å……è¶³
            news_df = data['news_data']
            if news_df.empty:
                logger.warning(f"è‚¡ç¥¨ {code} æ–°é—»æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡")
                continue
            
            # è®¡ç®—æƒ…ç»ªæŒ‡æ•°
            news_df_normalized = normalize_news_columns_local(news_df)
            sentiment_index_series, sentiment_df = stock_sentiment_analyzer.calculate_sentiment_index(news_df_normalized)
            
            if sentiment_index_series.empty:
                logger.warning(f"è‚¡ç¥¨ {code} æƒ…ç»ªæŒ‡æ•°è®¡ç®—å¤±è´¥ï¼Œè·³è¿‡")
                continue
            
            # è®¡ç®— Z-Score
            sentiment_values = sentiment_index_series.values
            if len(sentiment_values) < 5:
                logger.warning(f"è‚¡ç¥¨ {code} æƒ…ç»ªæ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
                continue
            
            mean = np.mean(sentiment_values)
            std = np.std(sentiment_values)
            z_score = (sentiment_values[-1] - mean) / std if std > 0 else 0
            
            # è·å–è‚¡ç¥¨åç§°
            basic_info = data['basic_info']
            stock_name = basic_info['name'].iloc[0] if not basic_info.empty else f'è‚¡ç¥¨{code}'
            
            # è·å–æœ€æ–°æ–°é—»æ ‡é¢˜
            latest_news = news_df_normalized.tail(1)
            latest_title = latest_news['title'].iloc[0] if not latest_news.empty else "æš‚æ— æ–°é—»"
            
            results.append({
                'code': code,
                'name': stock_name,
                'z_score': round(z_score, 2),
                'sentiment_score': round(sentiment_values[-1], 3),
                'latest_news': latest_title,
                'price_count': len(price_df),
                'news_count': len(news_df)
            })
            
            logger.info(f"è‚¡ç¥¨ {code} æ‰«æå®Œæˆ: Z-Score={z_score:.2f}")
            
        except Exception as e:
            logger.error(f"æ‰«æè‚¡ç¥¨ {code} å¤±è´¥: {e}")
            continue
    
    # æŒ‰ç»å¯¹å€¼æ’åº Z-Score
    results_df = pd.DataFrame(results)
    if not results_df.empty:
        results_df = results_df.sort_values('z_score', key=abs, ascending=False)
    
    logger.info(f"========== Alpha ç­›é€‰é›·è¾¾æ‰«æå®Œæˆï¼Œå…± {len(results_df)} åªè‚¡ç¥¨ ==========")
    return results_df

def normalize_news_columns_local(df_news):
    """
    æœ¬åœ°ç‰ˆæœ¬çš„normalize_news_columnså‡½æ•°
    æ ‡å‡†åŒ–æ–°é—»æ•°æ®çš„åˆ—åå’Œæ ¼å¼
    """
    if df_news.empty:
        return df_news
    
    df = df_news.copy()
    
    # ç¡®ä¿ date åˆ—æ˜¯ datetime ç±»å‹ï¼Œå¹¶æ ‡å‡†åŒ–ä¸ºæ—¥æœŸï¼ˆå»é™¤æ—¶é—´éƒ¨åˆ†ï¼‰
    if 'date' in df.columns:
        df['date'] = pd.to_datetime(df['date']).dt.normalize()
    
    # å¦‚æœæ²¡æœ‰ title åˆ—ï¼Œä½¿ç”¨ content çš„å‰50å­—ç¬¦ä½œä¸º title
    if 'title' not in df.columns and 'content' in df.columns:
        df['title'] = df['content'].apply(lambda x: str(x)[:50] + "..." if len(str(x)) > 50 else str(x))
    elif 'title' not in df.columns:
        df['title'] = "è‚¡å§å¸–å­"
    
    # ç¡®ä¿ content åˆ—å­˜åœ¨
    if 'content' not in df.columns:
        df['content'] = df['title']
    
    # ç¡®ä¿ reading/comments æˆ– view_count/comment_count åˆ—å­˜åœ¨
    if 'reading' not in df.columns and 'view_count' not in df.columns:
        df['reading'] = 1
    if 'comments' not in df.columns and 'comment_count' not in df.columns:
        df['comments'] = 1
        
    return df

@st.cache_data(ttl=600)
def get_market_sentiment_top(top_n=5):
    """
    è·å–å…¨å¸‚åœºæƒ…ç»ª Z-Score æœ€é«˜çš„ N åªè‚¡ç¥¨
    :param top_n: è¿”å›çš„è‚¡ç¥¨æ•°é‡
    :return: åŒ…å«è‚¡ç¥¨ä»£ç ã€åç§°ã€Z-Scoreã€æ ¸å¿ƒé€»è¾‘çš„DataFrame
    """
    try:
        logger = logging.getLogger(__name__)
        logger.info(f"å¼€å§‹æ‰«æå…¨å¸‚åœºæƒ…ç»ªå¼‚åŠ¨è‚¡ç¥¨ï¼Œç›®æ ‡æ•°é‡: {top_n}")
        
        stock_list_df = stock_crawler.get_stock_list()
        if stock_list_df.empty:
            return pd.DataFrame()
        
        results = []
        checked_count = 0
        max_check = 100
        
        for idx, row in stock_list_df.head(max_check).iterrows():
            stock_code = row['ä»£ç ']
            stock_name = row['åç§°']
            
            try:
                end_date = datetime.now()
                start_date = end_date - timedelta(days=30)
                start_date_str = start_date.strftime("%Y%m%d")
                end_date_str = end_date.strftime("%Y%m%d")
                
                stock_df = stock_crawler.get_stock_price(stock_code, start_date_str, end_date_str)
                if stock_df.empty or len(stock_df) < 10:
                    continue
                
                news_df = get_stock_news_akshare(stock_code, days=30)
                if news_df.empty:
                    continue
                
                news_df = normalize_news_columns_local(news_df)
                sentiment_index_series, sentiment_df = stock_sentiment_analyzer.calculate_sentiment_index(news_df)
                
                if sentiment_index_series.empty:
                    continue
                
                extreme_df = stock_sentiment_analyzer.detect_extreme_sentiment(
                    sentiment_index_series, 
                    window=20, 
                    threshold=2.0
                )
                
                if extreme_df.empty:
                    continue
                
                latest_extreme = extreme_df[extreme_df['extreme_signal'] != 'æ— '].tail(1)
                if latest_extreme.empty:
                    continue
                
                z_score = latest_extreme['z_score'].iloc[0]
                
                if abs(z_score) < 2.0:
                    continue
                
                latest_news = news_df.tail(1)
                if not latest_news.empty:
                    title = latest_news['title'].iloc[0]
                    summary = latest_news['content'].iloc[0] if 'content' in latest_news.columns else ""
                    
                    analysis_result = sentiment_analyzer.analyze_logic_and_sentiment(title, summary)
                    logic_summary = analysis_result.get('impact_summary', 'æš‚æ— åˆ†æ')
                else:
                    logic_summary = 'æš‚æ— æœ€æ–°æ–°é—»'
                
                results.append({
                    'code': stock_code,
                    'name': stock_name,
                    'z_score': z_score,
                    'sentiment_score': sentiment_index_series.iloc[-1],
                    'logic_summary': logic_summary
                })
                
                checked_count += 1
                if checked_count >= top_n * 2:
                    break
                    
            except Exception as e:
                logger.warning(f"åˆ†æè‚¡ç¥¨ {stock_code} å¤±è´¥: {e}")
                continue
        
        if not results:
            return pd.DataFrame()
        
        results_df = pd.DataFrame(results)
        results_df = results_df.sort_values('z_score', ascending=False).head(top_n)
        
        logger.info(f"æ‰«æå®Œæˆï¼Œæ‰¾åˆ° {len(results_df)} åªå¼‚åŠ¨è‚¡ç¥¨")
        return results_df
        
    except Exception as e:
        logger.error(f"è·å–å¸‚åœºæƒ…ç»ªå¼‚åŠ¨è‚¡ç¥¨å¤±è´¥: {e}")
        return pd.DataFrame()

@st.cache_data(ttl=1800)
def get_ai_strategy_insight(stock_code, sentiment_score, correlation, latest_momentum):
    """
    è·å– AI ç­–ç•¥æ´å¯Ÿï¼ˆæ ¸å¿ƒé€»è¾‘ã€é£é™©é¢„è­¦ã€T+1 å»ºè®®ä»“ä½ï¼‰
    :param stock_code: è‚¡ç¥¨ä»£ç 
    :param sentiment_score: å½“å‰æƒ…æ„Ÿåˆ†
    :param correlation: æƒ…ç»ª-è‚¡ä»·ç›¸å…³æ€§
    :param latest_momentum: æœ€æ–°æƒ…ç»ªåŠ¨é‡
    :return: åŒ…å«æ ¸å¿ƒé€»è¾‘ã€é£é™©é¢„è­¦ã€å»ºè®®ä»“ä½çš„å­—å…¸
    """
    try:
        logger = logging.getLogger(__name__)
        
        fundamental_metrics = stock_sentiment_analyzer.get_fundamental_metrics(stock_code)
        
        core_logic_parts = []
        risk_warnings = []
        
        if sentiment_score > 0.5:
            core_logic_parts.append("å½“å‰èˆ†æƒ…æƒ…ç»ªç§¯æ")
        elif sentiment_score < -0.5:
            core_logic_parts.append("å½“å‰èˆ†æƒ…æƒ…ç»ªæ¶ˆæ")
        
        if abs(correlation) > 0.5:
            direction = "æ­£ç›¸å…³" if correlation > 0 else "è´Ÿç›¸å…³"
            core_logic_parts.append(f"èˆ†æƒ…ä¸è‚¡ä»·{direction}æ˜¾è‘—")
        elif abs(correlation) < 0.1:
            risk_warnings.append("è¯¥è‚¡å—èˆ†æƒ…é©±åŠ¨æå¼±ï¼Œéœ€è°¨æ…å‚è€ƒ")
        
        if fundamental_metrics['is_fundamentally_healthy']:
            core_logic_parts.append("åŸºæœ¬é¢å¥åº·ï¼ˆROE > 8%ï¼‰")
        else:
            risk_warnings.append("åŸºæœ¬é¢ä¸€èˆ¬ï¼Œéœ€å…³æ³¨è´¢åŠ¡é£é™©")
        
        if latest_momentum > 0.1:
            core_logic_parts.append("æƒ…ç»ªåŠ¨é‡å‘ä¸Š")
        elif latest_momentum < -0.1:
            risk_warnings.append("æƒ…ç»ªåŠ¨é‡å‘ä¸‹ï¼Œéœ€è­¦æƒ•")
        
        core_logic = "ï¼›".join(core_logic_parts) if core_logic_parts else "æš‚æ— æ˜æ˜¾é©±åŠ¨é€»è¾‘"
        risk_warning = "ï¼›".join(risk_warnings) if risk_warnings else "æš‚æ— æ˜æ˜¾é£é™©"
        
        if sentiment_score > 0.6 and fundamental_metrics['is_fundamentally_healthy']:
            position_suggestion = "å»ºè®®ä»“ä½ï¼š30%-50%ï¼ˆæƒ…ç»ªç§¯æ+åŸºæœ¬é¢å¥åº·ï¼‰"
        elif sentiment_score > 0.3:
            position_suggestion = "å»ºè®®ä»“ä½ï¼š10%-30%ï¼ˆæƒ…ç»ªåç§¯æï¼‰"
        elif sentiment_score < -0.5:
            position_suggestion = "å»ºè®®ä»“ä½ï¼š0%-10%ï¼ˆæƒ…ç»ªæ¶ˆæï¼Œå»ºè®®è§‚æœ›ï¼‰"
        else:
            position_suggestion = "å»ºè®®ä»“ä½ï¼š10%-20%ï¼ˆä¸­æ€§åè°¨æ…ï¼‰"
        
        return {
            'core_logic': core_logic,
            'risk_warning': risk_warning,
            'position_suggestion': position_suggestion,
            'fundamental_metrics': fundamental_metrics
        }
        
    except Exception as e:
        logger.error(f"è·å– AI ç­–ç•¥æ´å¯Ÿå¤±è´¥: {e}")
        return {
            'core_logic': "åˆ†æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•",
            'risk_warning': "æ— æ³•è¯„ä¼°é£é™©",
            'position_suggestion': "å»ºè®®ä»“ä½ï¼š0%-10%ï¼ˆåˆ†æå¤±è´¥ï¼‰",
            'fundamental_metrics': {}
        }

def get_sentiment_color(sentiment_score, z_score=None):
    """
    æ ¹æ®æƒ…æ„Ÿåˆ†å’Œ Z-Score è¿”å›é¢œè‰²ï¼ˆé¢œè‰²æ·±æµ…åæ˜  Z-Score å¼ºåº¦ï¼‰
    :param sentiment_score: æƒ…æ„Ÿåˆ†ï¼ˆ-1 åˆ° 1ï¼‰
    :param z_score: Z-Scoreï¼ˆå¯é€‰ï¼Œç”¨äºè°ƒæ•´é¢œè‰²æ·±æµ…ï¼‰
    :return: é¢œè‰²å€¼
    """
    import numpy as np
    
    # å¤„ç†NaNå€¼
    if pd.isna(sentiment_score):
        sentiment_score = 0.0
    
    if sentiment_score > 0:
        base_color = [255, 0, 0]
    else:
        base_color = [0, 255, 0]
    
    if z_score is not None and not pd.isna(z_score):
        intensity = min(abs(z_score) / 3.0, 1.0)
    else:
        intensity = min(abs(sentiment_score), 1.0)
    
    # ç¡®ä¿intensityæ˜¯æœ‰æ•ˆæ•°å€¼
    if pd.isna(intensity):
        intensity = 0.5
    
    if sentiment_score > 0:
        r = 255
        g = int(255 * (1 - intensity))
        b = int(255 * (1 - intensity))
    else:
        r = int(255 * (1 - intensity))
        g = 255
        b = int(255 * (1 - intensity))
    
    return f'rgb({r}, {g}, {b})'

st.sidebar.title("è‚¡ç¥¨é€‰æ‹©")

@st.cache_data(ttl=7200)
def load_stock_list():
    try:
        return stock_crawler.get_stock_list()
    except Exception as e:
        logger = logging.getLogger(__name__)
        logger.error(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
        return pd.DataFrame()

stock_list_df = load_stock_list()

@st.cache_data
def get_company_to_code_mapping():
    if not stock_list_df.empty:
        return {row['åç§°']: row['ä»£ç '] for _, row in stock_list_df.iterrows()}
    return {}

company_to_code = get_company_to_code_mapping()

DEFAULT_STOCK_CODE = "600519"
DEFAULT_COMPANY_NAME = "è´µå·èŒ…å°"

search_method = st.sidebar.radio(
    "æœç´¢æ–¹å¼",
    ["é€‰æ‹©è‚¡ç¥¨", "è¾“å…¥å…¬å¸åç§°"]
)

selected_stock = None
stock_code = None

if search_method == "é€‰æ‹©è‚¡ç¥¨":
    if not stock_list_df.empty:
        stock_options = {f"{row['ä»£ç ']} - {row['åç§°']}": row['ä»£ç '] for _, row in stock_list_df.iterrows()}
        default_option = f"{DEFAULT_STOCK_CODE} - {DEFAULT_COMPANY_NAME}"
        default_index = list(stock_options.keys()).index(default_option) if default_option in stock_options else 0
        
        selected_stock = st.sidebar.selectbox(
            "é€‰æ‹©è‚¡ç¥¨",
            options=list(stock_options.keys()),
            index=default_index
        )
        
        stock_code = stock_options[selected_stock]
else:
    company_name = st.sidebar.text_input("è¾“å…¥å…¬å¸åç§°", DEFAULT_COMPANY_NAME)
    if company_name:
        if company_name in company_to_code:
            stock_code = company_to_code[company_name]
            st.sidebar.success(f"æ‰¾åˆ°åŒ¹é…çš„è‚¡ç¥¨ä»£ç : {stock_code}")
        else:
            matched_companies = [name for name in company_to_code.keys() if company_name in name]
            if matched_companies:
                selected_company = st.sidebar.selectbox(
                    "å¯èƒ½åŒ¹é…çš„å…¬å¸",
                    options=matched_companies
                )
                stock_code = company_to_code[selected_company]
            else:
                st.sidebar.warning(f"æœªæ‰¾åˆ°åŒ¹é…çš„å…¬å¸: {company_name}")
                stock_code = st.sidebar.text_input("æ‰‹åŠ¨è¾“å…¥è‚¡ç¥¨ä»£ç ", DEFAULT_STOCK_CODE)

st.sidebar.title("æ—¥æœŸèŒƒå›´")
start_date = st.sidebar.date_input("å¼€å§‹æ—¥æœŸ", value=pd.to_datetime("2024-01-01"))
end_date = st.sidebar.date_input("ç»“æŸæ—¥æœŸ", value=pd.to_datetime("today"))

start_date_str = start_date.strftime("%Y%m%d")
end_date_str = end_date.strftime("%Y%m%d")

st.sidebar.title("åˆ†æå‚æ•°")
correlation_lag = st.sidebar.slider("ç›¸å…³æ€§åˆ†ææ»åå¤©æ•°", 0, 5, 1)
divergence_window = st.sidebar.slider("èƒŒç¦»åˆ†æçª—å£å¤§å°", 5, 30, 10)

st.sidebar.title("å¡«å……ç­–ç•¥")
fill_method = st.sidebar.radio(
    "æƒ…ç»ªæŒ‡æ•°å¡«å……æ–¹æ³•",
    ["æ™ºèƒ½å¡«å……", "å‰å‘å¡«å……", "é›¶å€¼å¡«å……"],
    index=0
)

# æ˜ å°„æ˜¾ç¤ºåç§°åˆ°å®é™…æ–¹æ³•å
fill_method_map = {
    "æ™ºèƒ½å¡«å……": "smart",
    "å‰å‘å¡«å……": "forward",
    "é›¶å€¼å¡«å……": "zero"
}

# åªæœ‰åœ¨æ™ºèƒ½å¡«å……æ—¶æ˜¾ç¤ºé˜ˆå€¼æ»‘å—
forward_fill_threshold = 5
if fill_method == "æ™ºèƒ½å¡«å……":
    forward_fill_threshold = st.sidebar.slider(
        "å‰å‘å¡«å……æœ€å¤§è¿ç»­å¤©æ•°",
        1, 15, 5
    )

# ==================== Alpha Radar æ ¸å¿ƒåŠŸèƒ½ ====================

def get_multi_source_news(stock_code, days=30):
    """
    å¤šæºèåˆæ•°æ®è·å–ï¼šä¾æ¬¡å°è¯•æ–°é—»ã€å…¬å‘Šã€ç ”æŠ¥
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        days: è·å–å¤©æ•°
        
    Returns:
        DataFrame: åˆå¹¶åçš„æ–°é—»æ•°æ®
    """
    all_news = []
    
    print(f"\nğŸ“¡ {stock_code}: å¼€å§‹å¤šæºèåˆæ•°æ®è·å–...")
    
    # 1. æ–°é—» (News): akshare.stock_news_em
    try:
        print(f"   ğŸ“° å°è¯•è·å–æ–°é—»æ•°æ®...")
        df_news = ak.stock_news_em(symbol=stock_code)
        if not df_news.empty:
            df_news = df_news[['å‘å¸ƒæ—¶é—´', 'æ–°é—»æ ‡é¢˜', 'æ–°é—»å†…å®¹']].copy()
            df_news.rename(columns={'å‘å¸ƒæ—¶é—´': 'date', 'æ–°é—»æ ‡é¢˜': 'title', 'æ–°é—»å†…å®¹': 'content'}, inplace=True)
            df_news['source'] = 'news'
            df_news['weight'] = 1.0  # æ–°é—»æƒé‡
            all_news.append(df_news)
            print(f"   âœ… æ–°é—»æ•°æ®: {len(df_news)} æ¡")
        else:
            print(f"   âŒ æ–°é—»æ•°æ®ä¸ºç©º")
    except Exception as e:
        print(f"   âŒ æ–°é—»æ•°æ®è·å–å¤±è´¥: {e}")
    
    # 2. å…¬å‘Š (Notices): æš‚æ—¶æ³¨é‡Šï¼Œakshare å…¬å‘Šæ¥å£å¯èƒ½å·²å˜æ›´
    # try:
    #     print(f"   ğŸ“‹ å°è¯•è·å–å…¬å‘Šæ•°æ®...")
    #     df_notice = ak.stock_notice_report_em(symbol=stock_code)
    #     if not df_notice.empty:
    #         df_notice = df_notice[['å…¬å‘Šæ—¥æœŸ', 'å…¬å‘Šæ ‡é¢˜', 'å…¬å‘Šå†…å®¹']].copy()
    #         df_notice.rename(columns={'å…¬å‘Šæ—¥æœŸ': 'date', 'å…¬å‘Šæ ‡é¢˜': 'title', 'å…¬å‘Šå†…å®¹': 'content'}, inplace=True)
    #         df_notice['source'] = 'notice'
    #         df_notice['weight'] = 1.5  # å…¬å‘Šæƒé‡1.5å€
    #         all_news.append(df_notice)
    #         print(f"   âœ… å…¬å‘Šæ•°æ®: {len(df_notice)} æ¡ (æƒé‡1.5å€)")
    #     else:
    #         print(f"   âŒ å…¬å‘Šæ•°æ®ä¸ºç©º")
    # except Exception as e:
    #     print(f"   âŒ å…¬å‘Šæ•°æ®è·å–å¤±è´¥: {e}")
    
    # 3. ç ”æŠ¥ (Reports): æš‚æ—¶æ³¨é‡Šï¼Œakshare ç ”æŠ¥æ¥å£å¯èƒ½å·²å˜æ›´
    # try:
    #     print(f"   ğŸ“Š å°è¯•è·å–ç ”æŠ¥æ•°æ®...")
    #     df_report = ak.stock_research_report_em(symbol=stock_code)
    #     if not df_report.empty:
    #         df_report = df_report[['å‘å¸ƒæ—¥æœŸ', 'ç ”æŠ¥æ ‡é¢˜', 'ç ”æŠ¥å†…å®¹']].copy()
    #         df_report.rename(columns={'å‘å¸ƒæ—¥æœŸ': 'date', 'ç ”æŠ¥æ ‡é¢˜': 'title', 'ç ”æŠ¥å†…å®¹': 'content'}, inplace=True)
    #         df_report['source'] = 'report'
    #         df_report['weight'] = 1.0  # ç ”æŠ¥æƒé‡
    #         all_news.append(df_report)
    #         print(f"   âœ… ç ”æŠ¥æ•°æ®: {len(df_report)} æ¡")
    #     else:
    #         print(f"   âŒ ç ”æŠ¥æ•°æ®ä¸ºç©º")
    # except Exception as e:
    #     print(f"   âŒ ç ”æŠ¥æ•°æ®è·å–å¤±è´¥: {e}")
    
    # å…œåº•æœºåˆ¶ï¼šåªè¦ä¸‰è€…ä¹‹ä¸­ä»»æ„ä¸€ä¸ªè¿”å›äº†æœ‰æ•ˆæ•°æ®ï¼Œå°±ç»§ç»­
    if not all_news:
        print(f"   ğŸ’¥ {stock_code}: æ‰€æœ‰æ•°æ®æºå‡è¿”å›ç©ºæ•°æ®")
        return pd.DataFrame()
    
    # åˆå¹¶æ•°æ®
    df = pd.concat(all_news, ignore_index=True)
    print(f"   ğŸ“Š {stock_code}: å¤šæºèåˆå®Œæˆï¼Œæ€»è®¡ {len(df)} æ¡æ•°æ®")
    
    # å¤„ç†æ—¥æœŸæ ¼å¼
    df['date'] = pd.to_datetime(df['date'], errors='coerce')
    df = df.dropna(subset=['date'])
    
    # å»é‡
    df = df.drop_duplicates(subset=['date', 'title'], keep='first')
    
    # è¿‡æ»¤æ—¥æœŸèŒƒå›´
    end_date = pd.to_datetime(datetime.now())
    start_date = end_date - timedelta(days=days)
    df = df[(df['date'] >= start_date) & (df['date'] <= end_date)]
    
    print(f"   ğŸ“… {stock_code}: æ—¥æœŸè¿‡æ»¤åå‰©ä½™ {len(df)} æ¡æ•°æ®")
    
    return df

# å®šä¹‰è§‚å¯Ÿæ± ï¼š10-20åªçƒ­é—¨è‚¡ç¥¨ä»£ç 
TARGET_POOL = [
    "600519",  # è´µå·èŒ…å°
    "300750",  # å®å¾·æ—¶ä»£
    "002594",  # æ¯”äºšè¿ª
    "601318",  # ä¸­å›½å¹³å®‰
    "000858",  # äº”ç²®æ¶²
    "600036",  # æ‹›å•†é“¶è¡Œ
    "601012",  # éš†åŸºç»¿èƒ½
    "300059",  # ä¸œæ–¹è´¢å¯Œ
    "600276",  # æ’ç‘åŒ»è¯
    "000333",  # ç¾çš„é›†å›¢
    "601888",  # ä¸­å›½ä¸­å…
    "300015",  # çˆ±å°”çœ¼ç§‘
    "600887",  # ä¼Šåˆ©è‚¡ä»½
    "002415",  # æµ·åº·å¨è§†
    "600900",  # é•¿æ±Ÿç”µåŠ›
]

@st.cache_data(ttl=3600)  # 1å°æ—¶ç¼“å­˜
def scan_market_opportunities(stock_list):
    """
    æ‰«æå¸‚åœºæœºä¼šï¼šåŸºäºé»„é‡‘æ¨¡å‹ç®€ç‰ˆçš„è‡ªåŠ¨åŒ–ç­›é€‰
    
    Args:
        stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        
    Returns:
        DataFrame: ç­›é€‰å‡ºçš„è‚¡ç¥¨æ•°æ®ï¼ŒæŒ‰Z-Scoreé™åºæ’åˆ—
    """
    results = []
    end_date = datetime.now()
    start_date = end_date - timedelta(days=30)  # æ”¾å®½æ—¥æœŸé™åˆ¶ï¼š30å¤©æ•°æ®
    
    for stock_code in stock_list:
        try:
            print(f"\n{'='*60}")
            print(f"ğŸ” å¼€å§‹å¤„ç†è‚¡ç¥¨: {stock_code}")
            print(f"{'='*60}")
            
            # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            stock_info = stock_crawler.get_stock_basic_info(stock_code)
            if stock_info.empty:
                print(f"âŒ {stock_code}: è·å–åŸºæœ¬ä¿¡æ¯å¤±è´¥ï¼Œè¿”å›ç©ºDataFrame")
                continue
                
            stock_name = stock_info.iloc[0]['name'] if 'name' in stock_info.columns else stock_code
            print(f"âœ… {stock_code}: è‚¡ç¥¨åç§° = {stock_name}")
            
            # è·å–è‚¡ç¥¨ä»·æ ¼æ•°æ®
            print(f"ğŸ“Š {stock_code}: æ­£åœ¨è·å–ä»·æ ¼æ•°æ®...")
            print(f"   æ—¶é—´èŒƒå›´: {start_date.strftime('%Y-%m-%d')} åˆ° {end_date.strftime('%Y-%m-%d')}")
            
            stock_data = stock_crawler.get_stock_daily_data(stock_code, start_date.strftime('%Y%m%d'), end_date.strftime('%Y%m%d'))
            print(f"ğŸ“Š {stock_code}: è¡Œæƒ…æ•°æ®è¡Œæ•° = {len(stock_data)}")
            
            if stock_data.empty:
                print(f"âŒ {stock_code}: è¡Œæƒ…æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡")
                continue
            
            if len(stock_data) < 5:
                print(f"âŒ {stock_code}: è¡Œæƒ…æ•°æ®ä¸è¶³5å¤©ï¼ˆå½“å‰{len(stock_data)}å¤©ï¼‰ï¼Œè·³è¿‡")
                continue
            
            # è·å–æ–°é—»æ•°æ®ï¼ˆå¤šæºèåˆï¼‰
            news_data = get_multi_source_news(stock_code, days=30)
            
            if news_data is None or news_data.empty:
                print(f"âŒ {stock_code}: å¤šæºèåˆåä»æ— æ•°æ®")
                continue
            
            # æ ‡å‡†åŒ–åˆ—å
            news_data = normalize_news_columns_local(news_data)
            print(f"ğŸ“° {stock_code}: å¤šæºèåˆåæ–°é—»æ¡æ•° = {len(news_data)}")
            
            # å®¹é”™å¤„ç†ï¼šæ–°é—»æ•°é‡ä¸è¶³ï¼ˆå°‘äº5æ¡ï¼‰ï¼Œç›´æ¥è·³è¿‡
            if len(news_data) < 5:
                print(f"âŒ {stock_code}: æ–°é—»æ•°é‡ä¸è¶³5æ¡ï¼ˆå½“å‰{len(news_data)}æ¡ï¼‰ï¼Œè·³è¿‡")
                continue
            
            # è®¡ç®—æƒ…ç»ªåˆ†æ
            print(f"ğŸ§  {stock_code}: æ­£åœ¨è¿›è¡Œæƒ…ç»ªåˆ†æ...")
            
            sentiment_df = sentiment_analyzer.analyze_batch_news(news_data)
            
            if sentiment_df.empty:
                print(f"âŒ {stock_code}: æƒ…ç»ªåˆ†æç»“æœä¸ºç©ºï¼Œè·³è¿‡")
                continue
            
            print(f"ğŸ§  {stock_code}: æƒ…ç»ªåˆ†æè¡Œæ•° = {len(sentiment_df)}")
            
            # å¦‚æœæ–°é—»æ•°æ®åŒ…å«weightåˆ—ï¼Œä¸æƒ…ç»ªåˆ†æç»“æœåˆå¹¶
            if 'weight' in news_data.columns:
                print(f"âš–ï¸  {stock_code}: åº”ç”¨æ•°æ®æºæƒé‡...")
                # é€šè¿‡ç´¢å¼•åˆå¹¶weightä¿¡æ¯
                sentiment_df = sentiment_df.copy()
                sentiment_df['weight'] = news_data['weight'].values[:len(sentiment_df)]
                # åŠ æƒè®¡ç®—æƒ…ç»ªæŒ‡æ•°
                sentiment_df['weighted_sentiment'] = sentiment_df['sentiment_index'] * sentiment_df['weight']
                sentiment_mean = sentiment_df['weighted_sentiment'].mean()
                sentiment_std = sentiment_df['weighted_sentiment'].std()
                print(f"ğŸ“ˆ {stock_code}: åŠ æƒæƒ…ç»ªç»Ÿè®¡ - å‡å€¼={sentiment_mean:.4f}, æ ‡å‡†å·®={sentiment_std:.4f}")
            else:
                sentiment_mean = sentiment_df['sentiment_index'].mean()
                sentiment_std = sentiment_df['sentiment_index'].std()
                print(f"ğŸ“ˆ {stock_code}: æƒ…ç»ªç»Ÿè®¡ - å‡å€¼={sentiment_mean:.4f}, æ ‡å‡†å·®={sentiment_std:.4f}")
            
            # å®¹é”™å¤„ç†ï¼šæ— æ³•è®¡ç®—Z-Scoreï¼ˆæ ‡å‡†å·®ä¸º0ï¼‰ï¼Œç›´æ¥è·³è¿‡
            if sentiment_std == 0:
                print(f"âŒ {stock_code}: æƒ…ç»ªæ ‡å‡†å·®ä¸º0ï¼Œæ— æ³•è®¡ç®—Z-Scoreï¼Œè·³è¿‡")
                continue
            
            # è·å–å½“æ—¥æƒ…ç»ªæ•°æ®
            today = end_date.strftime('%Y-%m-%d')
            today_sentiment = sentiment_df[sentiment_df['date'] == today]
            
            print(f"ğŸ“… {stock_code}: æŸ¥æ‰¾å½“æ—¥æƒ…ç»ªæ•°æ®ï¼ˆæ—¥æœŸ={today}ï¼‰")
            print(f"ğŸ“… {stock_code}: å½“æ—¥æƒ…ç»ªæ•°æ®è¡Œæ•° = {len(today_sentiment)}")
            
            # å®¹é”™å¤„ç†ï¼šå½“æ—¥æ— æƒ…ç»ªæ•°æ®ï¼Œç›´æ¥è·³è¿‡
            if today_sentiment.empty:
                print(f"âŒ {stock_code}: å½“æ—¥æ— æƒ…ç»ªæ•°æ®ï¼Œè·³è¿‡")
                continue
            
            # å½“æ—¥æƒ…ç»ªå¾—åˆ†
            today_sentiment_score = today_sentiment['sentiment_index'].mean()
            
            # è®¡ç®—Sentiment Z-Score = (å½“æ—¥æƒ…ç»ª - å†å²å‡å€¼) / å†å²æ ‡å‡†å·®
            today_z_score = (today_sentiment_score - sentiment_mean) / sentiment_std
            
            print(f"ğŸ¯ {stock_code}: å½“æ—¥æƒ…ç»ªå¾—åˆ† = {today_sentiment_score:.4f}")
            print(f"ğŸ¯ {stock_code}: å½“æ—¥Z-Score = {today_z_score:.4f}")
            
            # è·å–å½“æ—¥è‚¡ä»·æ•°æ®
            today_stock_data = stock_data[stock_data['date'] == today]
            if today_stock_data.empty:
                print(f"âŒ {stock_code}: å½“æ—¥æ— è‚¡ä»·æ•°æ®ï¼Œè·³è¿‡")
                continue
            
            today_price_data = today_stock_data.iloc[-1]
            current_price = today_price_data['close']
            
            print(f"ğŸ’° {stock_code}: å½“å‰ä»·æ ¼ = {current_price:.2f}")
            
            # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            recent_5_days = stock_data.tail(5)
            
            # è¿‡å»5æ—¥è‚¡ä»·æ¶¨å¹…
            price_change_5d = (recent_5_days.iloc[-1]['close'] - recent_5_days.iloc[0]['close']) / recent_5_days.iloc[0]['close'] * 100
            
            # å½“æ—¥è‚¡ä»·æ¶¨å¹…
            yesterday_close = recent_5_days.iloc[-2]['close'] if len(recent_5_days) >= 2 else current_price
            price_change_1d = (current_price - yesterday_close) / yesterday_close * 100
            
            print(f"ğŸ“Š {stock_code}: 5æ—¥æ¶¨å¹… = {price_change_5d:.2f}%, å½“æ—¥æ¶¨å¹… = {price_change_1d:.2f}%")
            
            # åº”ç”¨é»„é‡‘æ¨¡å‹ç®€ç‰ˆç­›é€‰
            signals = []
            
            # ä¿¡å·Aï¼šæƒ…ç»ªçªå˜ (Z-Score > 2.0)
            if today_z_score > 2.0:
                signals.append("æƒ…ç»ªçªå˜")
                print(f"ğŸ”¥ {stock_code}: è§¦å‘ã€æƒ…ç»ªçªå˜ã€‘ä¿¡å·")
            
            # ä¿¡å·Bï¼šåº•éƒ¨åè½¬ (è‚¡ä»·5æ—¥æ¶¨å¹… < 0 ä¸” æƒ…ç»ªZ-Score > 0.5)
            if price_change_5d < 0 and today_z_score > 0.5:
                signals.append("åº•éƒ¨åè½¬")
                print(f"ğŸ“ˆ {stock_code}: è§¦å‘ã€åº•éƒ¨åè½¬ã€‘ä¿¡å·")
            
            # ä¿¡å·Cï¼šé‡ä»·å…±æŒ¯ (æƒ…ç»ª > 0.8 ä¸” è‚¡ä»·æ¶¨å¹… > 1%)
            if today_sentiment_score > 0.8 and price_change_1d > 1.0:
                signals.append("é‡ä»·å…±æŒ¯")
                print(f"ğŸ¤ {stock_code}: è§¦å‘ã€é‡ä»·å…±æŒ¯ã€‘ä¿¡å·")
            
            # åªä¿ç•™æœ‰ä¿¡å·çš„è‚¡ç¥¨
            if signals:
                results.append({
                    'è‚¡ç¥¨ä»£ç ': stock_code,
                    'è‚¡ç¥¨åç§°': stock_name,
                    'å½“å‰ä»·æ ¼': round(current_price, 2),
                    'æƒ…ç»ªå¾—åˆ†': round(today_sentiment_score, 3),
                    'Z-Score': round(today_z_score, 3),
                    'è§¦å‘ä¿¡å·': ', '.join(signals),
                    '5æ—¥æ¶¨è·Œ': round(price_change_5d, 2),
                    'å½“æ—¥æ¶¨è·Œ': round(price_change_1d, 2),
                    'æ–°é—»æ•°é‡': len(news_data)
                })
                print(f"âœ… {stock_code}: æˆåŠŸåŠ å…¥ç»“æœåˆ—è¡¨ï¼è§¦å‘ä¿¡å·: {signals}")
            else:
                print(f"â­ï¸  {stock_code}: æœªè§¦å‘ä»»ä½•ä¿¡å·ï¼Œè·³è¿‡")
        
        except Exception as e:
            # å®¹é”™å¤„ç†ï¼šæŸåªè‚¡ç¥¨è·å–å¤±è´¥ï¼Œç›´æ¥è·³è¿‡ï¼Œä¸¥ç¦è®©æ•´ä¸ªç¨‹åºå´©æºƒ
            print(f"ğŸ’¥ å¤„ç†è‚¡ç¥¨ {stock_code} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # è½¬æ¢ä¸ºDataFrameå¹¶æŒ‰Z-Scoreé™åºæ’åˆ—
    if results:
        result_df = pd.DataFrame(results)
        result_df = result_df.sort_values(by='Z-Score', ascending=False)
        return result_df
    
    return pd.DataFrame()

def analyze_with_deepseek(stock_code: str) -> str:
    """
    ä½¿ç”¨ DeepSeek åˆ†æä¸»åŠ›æ„å›¾
    :param stock_code: è‚¡ç¥¨ä»£ç 
    :return: ä¸»åŠ›æ„å›¾åˆ†æç»“æœ
    """
    try:
        from crawlers.stock_data_unified import fetch_comprehensive_data
        
        logger = logging.getLogger(__name__)
        logger.info(f"å¼€å§‹åˆ†æè‚¡ç¥¨ {stock_code} çš„ä¸»åŠ›æ„å›¾")
        
        data = fetch_comprehensive_data(stock_code)
        
        if not data['success']:
            return "æ•°æ®è·å–å¤±è´¥ï¼Œæ— æ³•åˆ†æ"
        
        news_df = data['news_data']
        if news_df.empty:
            return "æš‚æ— æ–°é—»æ•°æ®ï¼Œæ— æ³•åˆ†æ"
        
        latest_news = news_df.tail(10)
        
        analysis_results = []
        for idx, row in latest_news.iterrows():
            title = row.get('title', '')
            content = row.get('content', '')
            date = row.get('date', '')
            
            try:
                result = sentiment_analyzer.analyze_logic_and_sentiment(title, content)
                logic_category = result.get('logic_category', 'æ¶ˆæ¯é¢')
                impact_summary = result.get('impact_summary', 'æš‚æ— åˆ†æ')
                sentiment_score = result.get('sentiment_score', 0.0)
                
                analysis_results.append({
                    'date': date,
                    'title': title,
                    'logic_category': logic_category,
                    'impact_summary': impact_summary,
                    'sentiment_score': sentiment_score
                })
            except Exception as e:
                logger.warning(f"åˆ†ææ–°é—»å¤±è´¥: {e}")
                continue
        
        if not analysis_results:
            return "æ–°é—»åˆ†æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
        
        df_analysis = pd.DataFrame(analysis_results)
        
        logic_counts = df_analysis['logic_category'].value_counts()
        avg_sentiment = df_analysis['sentiment_score'].mean()
        
        main_force_intent = ""
        if avg_sentiment > 0.3:
            main_force_intent = "ä¸»åŠ›èµ„é‡‘å‘ˆç°å‡€æµå…¥æ€åŠ¿ï¼Œæƒ…ç»ªåä¹è§‚"
        elif avg_sentiment < -0.3:
            main_force_intent = "ä¸»åŠ›èµ„é‡‘å‘ˆç°å‡€æµå‡ºæ€åŠ¿ï¼Œæƒ…ç»ªåæ‚²è§‚"
        else:
            main_force_intent = "ä¸»åŠ›èµ„é‡‘è§‚æœ›ä¸ºä¸»ï¼Œæƒ…ç»ªä¸­æ€§"
        
        dominant_logic = logic_counts.index[0] if len(logic_counts) > 0 else "æ¶ˆæ¯é¢"
        
        summary = f"""
**ä¸»åŠ›æ„å›¾åˆ†ææŠ¥å‘Š**

**æ ¸å¿ƒåˆ¤æ–­ï¼š** {main_force_intent}

**ä¸»è¦é©±åŠ¨é€»è¾‘ï¼š** {dominant_logic}

**è¯¦ç»†åˆ†æï¼š**
"""
        
        for idx, row in df_analysis.head(5).iterrows():
            date_str = str(row['date'])[:10] if pd.notna(row['date']) else 'æœªçŸ¥æ—¥æœŸ'
            summary += f"\n- **{date_str}** [{row['logic_category']}]: {row['impact_summary']}"
        
        return summary
        
    except Exception as e:
        logger.error(f"ä¸»åŠ›æ„å›¾åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return f"åˆ†æå¤±è´¥: {str(e)}"

def render_alpha_radar():
    """
    æ¸²æŸ“Alphaé›·è¾¾æ¿å— - åŸºäº WATCHLIST
    """
    st.markdown("## ğŸš€ Alpha Radar - æ½œåŠ›è‚¡ç­›é€‰")
    st.markdown("*åŸºäºæƒ…ç»ª Z-Score çš„è‡ªåŠ¨åŒ–æœºä¼šå‘ç°å¼•æ“*")
    
    # åˆ·æ–°æŒ‰é’®
    col1, col2 = st.columns([1, 4])
    with col1:
        if st.button("ğŸ”„ åˆ·æ–°é›·è¾¾", type="primary"):
            st.cache_data.clear()
            st.rerun()
    
    with col2:
        st.caption(f"å®æ—¶æ‰«æ {len(WATCHLIST)} åªçƒ­é—¨è‚¡ç¥¨ï¼ŒåŸºäºæƒ…ç»ª Z-Score ç­›é€‰é«˜æ½œåŠ›æœºä¼š")
    
    # è·å–æ•°æ®
    with st.spinner("æ­£åœ¨æ‰«æå¸‚åœºæœºä¼š..."):
        alpha_data = run_alpha_screener()
    
    if alpha_data.empty:
        st.warning("ğŸ” ä»Šæ—¥æš‚æ— ç¬¦åˆæ¨¡å‹çš„è‚¡ç¥¨")
        st.info("æç¤ºï¼šåªæœ‰æ»¡è¶³æƒ…ç»ª Z-Score æ¡ä»¶çš„è‚¡ç¥¨æ‰ä¼šè¢«æ˜¾ç¤º")
        return
    
    # æ˜¾ç¤ºå‘ç°çš„æ½œåŠ›è‚¡æ•°é‡
    st.success(f"ğŸ¯ å‘ç° {len(alpha_data)} åªæ½œåŠ›è‚¡ï¼")
    
    # æ˜¾ç¤ºè¯¦ç»†æ•°æ®è¡¨æ ¼ï¼ˆå•è¡Œé€‰æ‹©æ¨¡å¼ï¼‰
    st.subheader("ğŸ“Š å®Œæ•´åˆ†ææ•°æ®ï¼ˆæŒ‰ Z-Score æ’åºï¼‰")
    st.caption("æ‰€æœ‰å‘ç°çš„æ½œåŠ›è‚¡ï¼Œå·²æŒ‰ Z-Score é™åºæ’åˆ—")
    
    # ä½¿ç”¨ column_config ç¾åŒ–è¡¨æ ¼
    column_config = {
        'code': st.column_config.TextColumn('è‚¡ç¥¨ä»£ç ', width='small'),
        'name': st.column_config.TextColumn('è‚¡ç¥¨åç§°', width='medium'),
        'z_score': st.column_config.NumberColumn('Z-Score', format='%.2f', width='small'),
        'sentiment_score': st.column_config.NumberColumn('æƒ…ç»ªå¾—åˆ†', format='%.3f', width='small'),
        'latest_news': st.column_config.TextColumn('æœ€æ–°æ–°é—»', width='large'),
        'price_count': st.column_config.NumberColumn('ä»·æ ¼æ•°æ®é‡', width='small'),
        'news_count': st.column_config.NumberColumn('æ–°é—»æ•°æ®é‡', width='small'),
    }
    
    # é€‰æ‹©æ‰€æœ‰åˆ—è¿›è¡Œæ˜¾ç¤º
    all_cols = list(alpha_data.columns)
    event = st.dataframe(
        alpha_data[all_cols], 
        width='stretch',
        column_config=column_config, 
        selection_mode="single-row",
        on_select="rerun",
        key="alpha_radar_table"
    )
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ‰«æè‚¡ç¥¨æ± ", f"{len(WATCHLIST)}åª")
    with col2:
        st.metric("å‘ç°ä¿¡å·", len(alpha_data))
    with col3:
        st.metric("å¹³å‡Z-Score", f"{alpha_data['z_score'].mean():.3f}")
    
    # æ¨¡å—ä¸‰ï¼šæŒ‰éœ€ AI åˆ†æ
    if event and event.selection and len(event.selection['rows']) > 0:
        selected_row_idx = event.selection['rows'][0]
        selected_stock = alpha_data.iloc[selected_row_idx]
        stock_code = selected_stock['code']
        stock_name = selected_stock['name']
        
        st.markdown("---")
        st.markdown(f"## ğŸ¤– ä¸»åŠ›æ„å›¾åˆ†æ - {stock_name} ({stock_code})")
        
        if st.button(f"ğŸ” åˆ†æ {stock_name} çš„ä¸»åŠ›æ„å›¾", key=f"analyze_{stock_code}"):
            with st.spinner("æ­£åœ¨è°ƒç”¨ DeepSeek è¿›è¡Œæ·±åº¦åˆ†æ..."):
                analysis_result = analyze_with_deepseek(stock_code)
                st.markdown(analysis_result)

# ==================== ä¸»è¦åº”ç”¨ç•Œé¢ ====================
st.title("ğŸ“ˆ è‚¡ç¥¨æƒ…ç»ªåˆ†æä¸è¶‹åŠ¿æ´å¯Ÿå·¥å…·")

# é¦–å…ˆæ˜¾ç¤ºAlphaé›·è¾¾åŠŸèƒ½
render_alpha_radar()

st.markdown("---")  # åˆ†éš”çº¿

@st.cache_data(ttl=600)
def render_market_sentiment_monitor():
    """
    æ¸²æŸ“é¡¶éƒ¨'å…¨åœºå¼‚åŠ¨ç›‘æ§å¸¦'ï¼šå®æ—¶æ»šåŠ¨æ˜¾ç¤ºæƒ…ç»ª Z-Score æœ€é«˜çš„ 5 åªè‚¡ç¥¨
    """
    try:
        st.markdown("### ğŸ”¥ å…¨åœºå¼‚åŠ¨ç›‘æ§å¸¦")
        
        market_top_df = get_market_sentiment_top(top_n=5)
        
        if market_top_df.empty:
            st.info("æš‚æ— å¸‚åœºå¼‚åŠ¨æ•°æ®ï¼Œè¯·ç¨ååˆ·æ–°")
            return
        
        for idx, row in market_top_df.iterrows():
            z_score = row['z_score']
            sentiment_score = row['sentiment_score']
            color = get_sentiment_color(sentiment_score, z_score)
            
            with st.container():
                cols = st.columns([2, 3, 2, 5])
                cols[0].markdown(f"**{row['name']}**")
                cols[0].caption(f"{row['code']}")
                
                sentiment_emoji = "ğŸ“ˆ" if sentiment_score > 0 else "ğŸ“‰"
                cols[1].metric(
                    f"æƒ…ç»ªåˆ† {sentiment_emoji}",
                    f"{sentiment_score:.3f}",
                    delta_color="normal" if sentiment_score > 0 else "inverse"
                )
                
                z_score_color = "ğŸ”´" if z_score > 0 else "ğŸŸ¢"
                cols[2].metric(
                    f"Z-Score {z_score_color}",
                    f"{z_score:.2f}",
                    delta_color="normal" if z_score > 0 else "inverse"
                )
                
                cols[3].markdown(f"<span style='color: {color}; font-weight: bold;'>{row['logic_summary']}</span>", unsafe_allow_html=True)
            
            st.divider()
        
    except Exception as e:
        st.error(f"æ¸²æŸ“å¸‚åœºå¼‚åŠ¨ç›‘æ§å¸¦å¤±è´¥: {e}")

render_market_sentiment_monitor()

@st.cache_data(ttl=300)
def load_stock_data(stock_code, start_date, end_date):
    try:
        return stock_crawler.get_stock_price(stock_code, start_date, end_date)
    except Exception as e:
        logger = logging.getLogger(__name__)
        logger.error(f"è·å–è‚¡ç¥¨ä»·æ ¼æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()

@st.cache_data(ttl=3600)
def load_stock_info(stock_code):
    try:
        return stock_crawler.get_stock_info(stock_code)
    except Exception as e:
        logger = logging.getLogger(__name__)
        logger.error(f"è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}")
        return pd.DataFrame()

@st.cache_data(ttl=1800)
def load_stock_news(stock_code, days=90):
    """
    ä¼˜å…ˆä½¿ç”¨AKShareå®˜æ–¹æ¥å£è·å–æ–°é—»æ•°æ®ï¼ˆç¨³å®šæ— åçˆ¬ï¼‰
    """
    try:
        df_news = get_stock_news_akshare(stock_code, days)
        if not df_news.empty:
            return df_news
    except Exception as e:
        st.warning(f"AKShareæ–°é—»æ¥å£è·å–å¤±è´¥: {e}ï¼Œå°è¯•ä½¿ç”¨å¤‡ç”¨æ•°æ®æº")
    
    try:
        return stock_crawler.get_stock_news(stock_code, days, use_mock_data=True)
    except Exception as e:
        st.error(f"æ‰€æœ‰æ–°é—»æ•°æ®æºå‡è·å–å¤±è´¥: {e}")
        return pd.DataFrame(columns=['date', 'title', 'content'])

@st.cache_data
def normalize_news_columns(df_news):
    """
    æ ‡å‡†åŒ–æ–°é—»æ•°æ®åˆ—åï¼Œç¡®ä¿åŒ…å«å¿…è¦çš„åˆ—
    """
    if df_news.empty:
        return df_news
    
    df = df_news.copy()
    
    # ç¡®ä¿ date åˆ—æ˜¯ datetime ç±»å‹ï¼Œå¹¶æ ‡å‡†åŒ–ä¸ºæ—¥æœŸï¼ˆå»é™¤æ—¶é—´éƒ¨åˆ†ï¼‰
    if 'date' in df.columns:
        df['date'] = pd.to_datetime(df['date']).dt.normalize()
    
    # å¦‚æœæ²¡æœ‰ title åˆ—ï¼Œä½¿ç”¨ content çš„å‰50å­—ç¬¦ä½œä¸º title
    if 'title' not in df.columns and 'content' in df.columns:
        df['title'] = df['content'].apply(lambda x: str(x)[:50] + "..." if len(str(x)) > 50 else str(x))
    elif 'title' not in df.columns:
        df['title'] = "è‚¡å§å¸–å­"
    
    # ç¡®ä¿ content åˆ—å­˜åœ¨
    if 'content' not in df.columns:
        df['content'] = ""
    
    # ç¡®ä¿æœ‰ view_count åˆ—
    if 'view_count' not in df.columns:
        if 'reading' in df.columns:
            df['view_count'] = df['reading']
        else:
            df['view_count'] = 1
    
    # ç¡®ä¿æœ‰ comment_count åˆ—
    if 'comment_count' not in df.columns:
        if 'comments' in df.columns:
            df['comment_count'] = df['comments']
        else:
            df['comment_count'] = 1
    
    return df

@st.cache_data
def calculate_daily_sentiment(news_df):
    sentiment_index_series, sentiment_df = stock_sentiment_analyzer.calculate_sentiment_index(news_df)
    return sentiment_index_series, sentiment_df

@st.cache_data
def fill_missing_sentiment(sentiment_df, trading_dates, fill_method='smart', forward_fill_threshold=5):
    """
    å¡«å……ç¼ºå¤±æ—¥æœŸçš„æƒ…ç»ªæŒ‡æ•°å€¼ï¼Œç¡®ä¿æ¯å¤©éƒ½æœ‰æƒ…ç»ªå€¼
    :param sentiment_df: æƒ…ç»ªæ•°æ®DataFrameï¼ŒåŒ…å« date å’Œ sentiment_index åˆ—
    :param trading_dates: å®Œæ•´çš„äº¤æ˜“æ—¥åˆ—è¡¨
    :param fill_method: å¡«å……æ–¹æ³•ï¼Œ'forward'ï¼ˆå‰å‘å¡«å……ï¼‰ã€'zero'ï¼ˆå¡«å……ä¸º0ï¼‰æˆ– 'smart'ï¼ˆæ™ºèƒ½å¡«å……ï¼‰
    :param forward_fill_threshold: æ™ºèƒ½å¡«å……æ—¶ï¼Œå‰å‘å¡«å……çš„æœ€å¤§è¿ç»­å¤©æ•°é˜ˆå€¼
    :return: å¡«å……åçš„æƒ…ç»ªæ•°æ®DataFrame
    """
    if sentiment_df.empty:
        return sentiment_df
    
    df = sentiment_df.copy()
    df['date'] = pd.to_datetime(df['date'])
    
    # ä½¿ç”¨å®Œæ•´çš„äº¤æ˜“æ—¥åˆ—è¡¨åˆ›å»ºDataFrame
    full_df = pd.DataFrame({'date': trading_dates})
    
    merged_df = pd.merge(full_df, df, on='date', how='left')
    
    if fill_method == 'smart':
        # æ™ºèƒ½å¡«å……ï¼šè¿ç»­ç¼ºå¤±å¤©æ•°å°äºé˜ˆå€¼æ—¶ä½¿ç”¨å‰å‘å¡«å……ï¼Œè¶…è¿‡é˜ˆå€¼æ—¶ä½¿ç”¨0å¡«å……
        # è®¡ç®—è¿ç»­ç¼ºå¤±å¤©æ•°
        merged_df['is_missing'] = merged_df['sentiment_index'].isna()
        merged_df['group_id'] = (merged_df['is_missing'] != merged_df['is_missing'].shift()).cumsum()
        
        # å¯¹æ¯ä¸ªç¼ºå¤±å€¼ç»„è¿›è¡Œå¤„ç†
        def smart_fill_group(group):
            if not group['is_missing'].any():
                return group
            
            # è®¡ç®—å½“å‰ç»„çš„è¿ç»­ç¼ºå¤±å¤©æ•°
            consecutive_missing_days = len(group)
            
            if consecutive_missing_days <= forward_fill_threshold:
                # è¿ç»­ç¼ºå¤±å¤©æ•°å°äºç­‰äºé˜ˆå€¼ï¼Œä½¿ç”¨å‰å‘å¡«å……
                group['sentiment_index'] = group['sentiment_index'].ffill()
                if 'sentiment_momentum' in group.columns:
                    group['sentiment_momentum'] = group['sentiment_momentum'].ffill()
            else:
                # è¿ç»­ç¼ºå¤±å¤©æ•°è¶…è¿‡é˜ˆå€¼ï¼Œä½¿ç”¨0å¡«å……
                group['sentiment_index'] = group['sentiment_index'].fillna(0)
                if 'sentiment_momentum' in group.columns:
                    group['sentiment_momentum'] = group['sentiment_momentum'].fillna(0)
            
            return group
        
        # åº”ç”¨æ™ºèƒ½å¡«å……
        merged_df = merged_df.groupby('group_id').apply(smart_fill_group, include_groups=False)
        
        # å¤„ç†å¯èƒ½çš„åˆå§‹ç¼ºå¤±å€¼ï¼ˆå‰å‘å¡«å……æ— æ³•å¤„ç†çš„æƒ…å†µï¼‰
        merged_df['sentiment_index'] = merged_df['sentiment_index'].fillna(0)
        if 'sentiment_momentum' in merged_df.columns:
            merged_df['sentiment_momentum'] = merged_df['sentiment_momentum'].fillna(0)
            
        # æ¸…ç†è¾…åŠ©åˆ—ï¼ˆåªåœ¨åˆ—å­˜åœ¨æ—¶æ‰åˆ é™¤ï¼‰
        columns_to_drop = ['is_missing']
        if 'group_id' in merged_df.columns:
            columns_to_drop.append('group_id')
        merged_df = merged_df.drop(columns_to_drop, axis=1)
        
    elif fill_method == 'forward':
        # ä¼ ç»Ÿå‰å‘å¡«å……
        merged_df['sentiment_index'] = merged_df['sentiment_index'].ffill().fillna(0)
        if 'sentiment_momentum' in merged_df.columns:
            merged_df['sentiment_momentum'] = merged_df['sentiment_momentum'].ffill().fillna(0)
    else:
        # å¡«å……ä¸º0
        merged_df['sentiment_index'] = merged_df['sentiment_index'].fillna(0)
        if 'sentiment_momentum' in merged_df.columns:
            merged_df['sentiment_momentum'] = merged_df['sentiment_momentum'].fillna(0)
    
    return merged_df

@st.cache_data
def detect_divergence(df_price, sentiment_index_series, divergence_window):
    return stock_sentiment_analyzer.detect_divergence(df_price, sentiment_index_series, divergence_window)

@st.cache_data
def calculate_sentiment_correlation(combined_df):
    if len(combined_df) > 1:
        correlation = combined_df['close'].corr(combined_df['sentiment_index'])
        return correlation
    return 0

if stock_code:
    try:
        end_date = datetime.now()
        start_date = end_date - timedelta(days=90)
        start_date_str = start_date.strftime("%Y%m%d")
        end_date_str = end_date.strftime("%Y%m%d")
        
        stock_df = load_stock_data(stock_code, start_date_str, end_date_str)
        stock_info = load_stock_info(stock_code)
        
        if stock_info:
            st.subheader("è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯")
            info_cols = st.columns(4)
            info_cols[0].metric("è‚¡ç¥¨ä»£ç ", stock_info.get("è‚¡ç¥¨ä»£ç ", stock_code))
            info_cols[1].metric("è‚¡ç¥¨åç§°", stock_info.get("è‚¡ç¥¨åç§°", "æœªçŸ¥"))
            info_cols[2].metric("è¡Œä¸š", stock_info.get("è¡Œä¸š", "æœªçŸ¥"))
            info_cols[3].metric("åœ°åŒº", stock_info.get("åœ°åŒº", "æœªçŸ¥"))
        
        # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¯æŠ˜å ï¼‰
        with st.expander("ğŸ“Š ç¼“å­˜æ€§èƒ½ç»Ÿè®¡"):
            cache_stats = sentiment_analyzer.get_cache_stats()
            cache_cols = st.columns(4)
            cache_cols[0].metric("æƒ…æ„Ÿç¼“å­˜å¤§å°", cache_stats['sentiment_cache_size'])
            cache_cols[1].metric("æ‰¹é‡ç¼“å­˜å¤§å°", cache_stats['batch_cache_size'])
            cache_cols[2].metric("ç¼“å­˜å‘½ä¸­ç‡", f"{cache_stats['cache_hit_rate']:.2%}")
            cache_cols[3].metric("æ‰¹é‡ç¼“å­˜å‘½ä¸­ç‡", f"{cache_stats['batch_cache_hit_rate']:.2%}")
            
            if st.button("æ¸…ç©ºç¼“å­˜"):
                sentiment_analyzer.clear_cache()
                st.success("ç¼“å­˜å·²æ¸…ç©ºï¼")
                st.rerun()
        
        if not stock_df.empty:
            st.subheader("è‚¡ä»·èµ°åŠ¿ä¸èˆ†æƒ…åˆ†æ")
            
            news_df = load_stock_news(stock_code, days=90)
            
            if not news_df.empty:
                st.info("ğŸ“° æ•°æ®æ¥æºï¼šä¸œæ–¹è´¢å¯Œå®˜æ–¹æ–°é—» (AKShare æ¥å£ï¼Œç¨³å®šæ— åçˆ¬)")
                # æ ‡å‡†åŒ–æ–°é—»æ•°æ®åˆ—å
                news_df = normalize_news_columns(news_df)
                
                sentiment_index_series, sentiment_df = calculate_daily_sentiment(news_df)
                
                # å¡«å……ç¼ºå¤±æ—¥æœŸçš„æƒ…ç»ªæŒ‡æ•°å€¼
                if not sentiment_df.empty:
                    # ä»è‚¡ç¥¨æ•°æ®ä¸­è·å–å®Œæ•´çš„äº¤æ˜“æ—¥åˆ—è¡¨
                    df_price = stock_df.copy()
                    df_price = df_price.rename(columns={
                        'æ—¥æœŸ': 'date',
                        'å¼€ç›˜': 'open',
                        'æ”¶ç›˜ä»·': 'close',
                        'æœ€é«˜': 'high',
                        'æœ€ä½': 'low',
                        'æˆäº¤é‡': 'volume'
                    })
                    df_price['date'] = pd.to_datetime(df_price['date']).dt.normalize()
                    trading_dates = df_price['date'].tolist()
                    
                    sentiment_df_filled = fill_missing_sentiment(
                        sentiment_df, 
                        trading_dates, 
                        fill_method=fill_method_map[fill_method],
                        forward_fill_threshold=forward_fill_threshold
                    )
                    sentiment_index_series_filled = sentiment_df_filled.set_index('date')['sentiment_index']
                    st.info(f"ğŸ“Š æƒ…ç»ªæ•°æ®ï¼šåŸå§‹ {len(sentiment_df)} å¤©ï¼Œå¡«å……å {len(sentiment_df_filled)} å¤©")
                    st.info(f"ğŸ”§ å¡«å……ç­–ç•¥ï¼š{fill_method}" + (f" (é˜ˆå€¼ï¼š{forward_fill_threshold}å¤©)" if fill_method == "æ™ºèƒ½å¡«å……" else ""))
                    st.info("æƒ…ç»ªæŒ‡æ•°å·²è¿ç»­å¡«å……ï¼ˆæ— æ–°é—»æ—¥ç»§æ‰¿å‰å€¼ï¼‰ï¼ŒçœŸå®æ–°é—»æ—¥ç”¨æ·±è‰²æ ‡è®°")
                else:
                    # å¦‚æœæƒ…ç»ªæ•°æ®ä¸ºç©ºï¼Œä½¿ç”¨0å€¼å¡«å……æ‰€æœ‰äº¤æ˜“æ—¥
                    df_price = stock_df.copy()
                    df_price = df_price.rename(columns={
                        'æ—¥æœŸ': 'date',
                        'å¼€ç›˜': 'open',
                        'æ”¶ç›˜ä»·': 'close',
                        'æœ€é«˜': 'high',
                        'æœ€ä½': 'low',
                        'æˆäº¤é‡': 'volume'
                    })
                    df_price['date'] = pd.to_datetime(df_price['date']).dt.normalize()
                    trading_dates = df_price['date'].tolist()
                    
                    sentiment_df_filled = pd.DataFrame({
                        'date': trading_dates,
                        'sentiment_index': [0] * len(trading_dates),
                        'sentiment_momentum': [0] * len(trading_dates)
                    })
                    sentiment_index_series_filled = sentiment_df_filled.set_index('date')['sentiment_index']
                    st.info(f"ğŸ“Š æƒ…ç»ªæ•°æ®ï¼šåŸå§‹ 0 å¤©ï¼Œå¡«å……å {len(sentiment_df_filled)} å¤©")
                    st.info(f"ğŸ”§ å¡«å……ç­–ç•¥ï¼š{fill_method}" + (f" (é˜ˆå€¼ï¼š{forward_fill_threshold}å¤©)" if fill_method == "æ™ºèƒ½å¡«å……" else ""))
                    st.info("æƒ…ç»ªæŒ‡æ•°å·²è¿ç»­å¡«å……ï¼ˆæ— æ–°é—»æ—¥ç»§æ‰¿å‰å€¼ï¼‰ï¼ŒçœŸå®æ–°é—»æ—¥ç”¨æ·±è‰²æ ‡è®°")
                
                df_price = stock_df.copy()
                df_price = df_price.rename(columns={
                    'æ—¥æœŸ': 'date',
                    'å¼€ç›˜': 'open',
                    'æ”¶ç›˜ä»·': 'close',
                    'æœ€é«˜': 'high',
                    'æœ€ä½': 'low',
                    'æˆäº¤é‡': 'volume'
                })
                df_price['date'] = pd.to_datetime(df_price['date']).dt.normalize()
                
                df_price['pct_change'] = df_price['close'].pct_change() * 100
                
                if df_price.empty or sentiment_index_series_filled.empty:
                    st.error("è‚¡ä»·æˆ–æƒ…ç»ªæ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–æ—¥æœŸèŒƒå›´")
                    st.stop()
                
                combined_df = detect_divergence(df_price, sentiment_index_series_filled, divergence_window)
                
                if not sentiment_df_filled.empty:
                    latest_sentiment = sentiment_df_filled['sentiment_index'].iloc[-1] if len(sentiment_df_filled) > 0 else 0
                    latest_momentum = sentiment_df_filled['sentiment_momentum'].iloc[-1] if len(sentiment_df_filled) > 1 else 0
                    
                    correlation = calculate_sentiment_correlation(combined_df)
            
            if 'combined_df' in locals() and not combined_df.empty:
                fig = make_subplots(specs=[[{"secondary_y": True}]])
                
                required_columns = ['date', 'open', 'high', 'low', 'close', 'sentiment_index']
                missing_columns = [col for col in required_columns if col not in combined_df.columns]
                
                if missing_columns:
                    st.error(f"ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_columns}")
                    st.write("å¯ç”¨åˆ—åï¼š", combined_df.columns.tolist())
                else:
                    fig.add_trace(
                        go.Candlestick(
                            x=combined_df['date'],
                            open=combined_df['open'],
                            high=combined_df['high'],
                            low=combined_df['low'],
                            close=combined_df['close'],
                            name='Kçº¿å›¾'
                        ),
                        secondary_y=False,
                    )
                    
                    # åŒºåˆ†çœŸå®æ–°é—»æ—¥å’Œå¡«å……æ—¥
                    # æ£€æŸ¥sentiment_dfçš„åˆ—åå¹¶åˆ›å»ºè¾…åŠ©åˆ—æ¥æ ‡è®°çœŸå®æ–°é—»æ—¥
                    if not sentiment_df.empty and 'date' in sentiment_df.columns and 'sentiment_index' in sentiment_df.columns:
                        df_with_indicator = combined_df.merge(
                            sentiment_df[['date', 'sentiment_index']].rename(columns={'sentiment_index': 'real_sentiment'}),
                            on='date',
                            how='left'
                        )
                        df_with_indicator['is_real_news'] = ~df_with_indicator['real_sentiment'].isna()
                    else:
                        # å¦‚æœsentiment_dfæ²¡æœ‰æ­£ç¡®çš„åˆ—ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„æ ‡è¯†
                        df_with_indicator = combined_df.copy()
                        df_with_indicator['real_sentiment'] = np.nan
                        df_with_indicator['is_real_news'] = False
                    
                    # è®¡ç®— Z-Score ç”¨äºé¢œè‰²æ·±æµ…
                    sentiment_mean = df_with_indicator['sentiment_index'].mean()
                    sentiment_std = df_with_indicator['sentiment_index'].std()
                    df_with_indicator['z_score'] = (df_with_indicator['sentiment_index'] - sentiment_mean) / sentiment_std
                    
                    # ä¸ºæ¯ä¸ªæ•°æ®ç‚¹è®¡ç®—é¢œè‰²ï¼ˆåŸºäºæƒ…æ„Ÿåˆ†å’Œ Z-Scoreï¼‰
                    df_with_indicator['color'] = df_with_indicator.apply(
                        lambda row: get_sentiment_color(row['sentiment_index'], row['z_score']),
                        axis=1
                    )
                    
                    # åˆ†ç¦»çœŸå®æ–°é—»æ—¥å’Œå¡«å……æ—¥çš„æ•°æ®
                    real_news_data = df_with_indicator[df_with_indicator['is_real_news']]
                    filled_data = df_with_indicator[~df_with_indicator['is_real_news']]
                    
                    # å…ˆç»˜åˆ¶å¡«å……æ—¥çš„æ•°æ®ï¼ˆä½œä¸ºèƒŒæ™¯ï¼‰
                    if not filled_data.empty:
                        fig.add_trace(
                            go.Scatter(
                                x=filled_data['date'],
                                y=filled_data['sentiment_index'],
                                name='å¡«å……çš„æƒ…ç»ªæŒ‡æ•°',
                                line=dict(color='lightgray', width=1, dash='dash'),
                                opacity=0.3
                            ),
                            secondary_y=True,
                        )
                    
                    # å†ç»˜åˆ¶çœŸå®æ–°é—»æ—¥çš„æ•°æ®ï¼ˆä½¿ç”¨åŠ¨æ€é¢œè‰²ï¼‰
                    if not real_news_data.empty:
                        fig.add_trace(
                            go.Scatter(
                                x=real_news_data['date'],
                                y=real_news_data['sentiment_index'],
                                name='çœŸå®çš„æƒ…ç»ªæŒ‡æ•°',
                                mode='lines+markers',
                                line=dict(color='gray', width=1),
                                marker=dict(
                                    color=real_news_data['color'],
                                    size=6,
                                    line=dict(color='white', width=1)
                                ),
                                opacity=0.9,
                                customdata=real_news_data[['z_score', 'sentiment_index']],
                                hovertemplate='<b>æ—¥æœŸ</b>: %{x}<br>' +
                                              '<b>æƒ…ç»ªåˆ†</b>: %{customdata[1]:.3f}<br>' +
                                              '<b>Z-Score</b>: %{customdata[0]:.2f}<extra></extra>'
                            ),
                            secondary_y=True,
                        )
                    # å¦‚æœæ²¡æœ‰çœŸå®æ–°é—»æ—¥æ•°æ®ï¼Œç»˜åˆ¶æ‰€æœ‰æ•°æ®
                    elif df_with_indicator.shape[0] > 0:
                        fig.add_trace(
                            go.Scatter(
                                x=df_with_indicator['date'],
                                y=df_with_indicator['sentiment_index'],
                                name='æƒ…ç»ªæŒ‡æ•°ï¼ˆå…¨éƒ¨å¡«å……ï¼‰',
                                line=dict(color='lightgray', width=1, dash='dash'),
                                opacity=0.5
                            ),
                            secondary_y=True,
                        )
                
                    if 'signal' in combined_df.columns:
                        top_divergence = combined_df[combined_df['signal'] == 'æ½œåœ¨å–å‡º']
                        if not top_divergence.empty:
                            fig.add_trace(
                                go.Scatter(
                                    x=top_divergence['date'],
                                    y=top_divergence['high'],
                                    mode='markers',
                                    name='æ½œåœ¨å–å‡º',
                                    marker=dict(color='purple', size=12, symbol='triangle-up')
                                ),
                                secondary_y=False,
                            )
                        
                        bottom_divergence = combined_df[combined_df['signal'] == 'æ½œåœ¨ä¹°å…¥']
                        if not bottom_divergence.empty:
                            fig.add_trace(
                                go.Scatter(
                                    x=bottom_divergence['date'],
                                    y=bottom_divergence['low'],
                                    mode='markers',
                                    name='æ½œåœ¨ä¹°å…¥',
                                    marker=dict(color='orange', size=12, symbol='triangle-down')
                                ),
                                secondary_y=False,
                            )
                    
                    fig.update_layout(
                        title=f'{stock_info.get("è‚¡ç¥¨åç§°", stock_code)} è‚¡ä»·èµ°åŠ¿ä¸æƒ…ç»ªåˆ†æ',
                        hovermode='x unified',
                        xaxis_rangeslider_visible=False,
                        height=600
                    )
                    
                    fig.update_yaxes(title_text='è‚¡ä»· (å…ƒ)', secondary_y=False)
                    fig.update_yaxes(title_text='æƒ…ç»ªæŒ‡æ•° (-1 åˆ° 1)', secondary_y=True)
                    
                    st.plotly_chart(fig, width='stretch')
                    
                    st.subheader("ğŸ¤– AI ç­–ç•¥æ´å¯Ÿ")
                    
                    if 'latest_sentiment' in locals() and 'correlation' in locals() and 'latest_momentum' in locals():
                        ai_insight = get_ai_strategy_insight(
                            stock_code, 
                            latest_sentiment, 
                            correlation, 
                            latest_momentum
                        )
                        
                        insight_cols = st.columns(3)
                        
                        with insight_cols[0]:
                            st.markdown("### ğŸ’¡ æ ¸å¿ƒé€»è¾‘")
                            st.info(ai_insight['core_logic'])
                        
                        with insight_cols[1]:
                            st.markdown("### âš ï¸ é£é™©é¢„è­¦")
                            st.warning(ai_insight['risk_warning'])
                        
                        with insight_cols[2]:
                            st.markdown("### ğŸ“Š T+1 å»ºè®®ä»“ä½")
                            st.success(ai_insight['position_suggestion'])
                        
                        st.divider()
                        
                        if ai_insight['fundamental_metrics']:
                            st.markdown("### ğŸ“ˆ åŸºæœ¬é¢æŒ‡æ ‡")
                            fund_cols = st.columns(3)
                            fund_cols[0].metric("ROE", f"{ai_insight['fundamental_metrics']['roe']:.2f}%")
                            fund_cols[1].metric("æ¯›åˆ©ç‡", f"{ai_insight['fundamental_metrics']['gross_margin']:.2f}%")
                            fund_cols[2].metric("è´Ÿå€ºç‡", f"{ai_insight['fundamental_metrics']['debt_ratio']:.2f}%")
                    else:
                        st.info("æ­£åœ¨è®¡ç®— AI ç­–ç•¥æ´å¯Ÿ...")
                    
                    st.subheader("åˆ†æç»“æœæ‘˜è¦")
                    
                    st.markdown("### æƒ…ç»ª-è‚¡ä»·ç›¸å…³æ€§åˆ†æ")
                    corr_cols = st.columns(3)
                    corr_cols[0].metric("ç›¸å…³ç³»æ•°", f"{correlation:.3f}" if 'correlation' in locals() else "N/A")
                    corr_cols[1].metric("æœ€æ–°æƒ…ç»ªæŒ‡æ•°", f"{latest_sentiment:.3f}" if 'latest_sentiment' in locals() else "N/A")
                    corr_cols[2].metric("æƒ…ç»ªåŠ¨é‡", f"{latest_momentum:.3f}" if 'latest_momentum' in locals() else "N/A")
                    
                    if 'correlation' in locals():
                        if correlation > 0.5:
                            st.success("æƒ…ç»ªä¸è‚¡ä»·å‘ˆç°å¼ºæ­£ç›¸å…³ï¼Œæƒ…ç»ªå˜åŒ–å¯èƒ½å¼•é¢†è‚¡ä»·èµ°åŠ¿")
                        elif correlation < -0.5:
                            st.success("æƒ…ç»ªä¸è‚¡ä»·å‘ˆç°å¼ºè´Ÿç›¸å…³ï¼Œæƒ…ç»ªå˜åŒ–å¯èƒ½ä¸è‚¡ä»·åå‘å˜åŠ¨")
                        else:
                            st.info("æƒ…ç»ªä¸è‚¡ä»·ç›¸å…³æ€§è¾ƒå¼±ï¼Œå»ºè®®ç»“åˆå…¶ä»–æŒ‡æ ‡åˆ†æ")
                    
                    st.markdown("### èƒŒç¦»ä¿¡å·åˆ†æ")
                    signal_cols = st.columns(2)
                    
                    if 'signal' in combined_df.columns:
                        sell_signals = len(combined_df[combined_df['signal'].str.contains('å–å‡º|é¡¶èƒŒç¦»', na=False)])
                        buy_signals = len(combined_df[combined_df['signal'].str.contains('ä¹°å…¥|åº•èƒŒç¦»', na=False)])
                        
                        signal_cols[0].metric("æ½œåœ¨å–å‡ºä¿¡å·", sell_signals)
                        signal_cols[1].metric("æ½œåœ¨ä¹°å…¥ä¿¡å·", buy_signals)
                        
                        if 'signal' in combined_df.columns and not combined_df[combined_df['signal'].notna()].empty:
                            latest_signal = combined_df[combined_df['signal'].notna()].iloc[-1]
                            st.write(f"æœ€æ–°èƒŒç¦»ä¿¡å·ï¼š{latest_signal['signal']} ï¼ˆæ—¥æœŸï¼š{latest_signal['date']}ï¼‰")
                            st.dataframe(
                                combined_df[['date', 'close', 'sentiment_index', 'signal']].dropna(subset=['signal']).fillna(''),
                                width=1000,
                                hide_index=True
                            )
                        else:
                            st.write("æš‚æ— æ£€æµ‹åˆ°èƒŒç¦»ä¿¡å·")
                    else:
                        signal_cols[0].metric("æ½œåœ¨å–å‡ºä¿¡å·", 0)
                        signal_cols[1].metric("æ½œåœ¨ä¹°å…¥ä¿¡å·", 0)
            
            st.subheader("è¯¦ç»†æ•°æ®")
            
            display_df = combined_df.copy()
            
            # æ›¿æ¢NaNå€¼ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œé¿å…æ˜¾ç¤º"nan"
            display_df = display_df.fillna('')
            
            if 'date' in display_df.columns:
                display_df['æ—¥æœŸ'] = display_df['date']
            if 'open' in display_df.columns:
                display_df['å¼€ç›˜'] = display_df['open']
            if 'close' in display_df.columns:
                display_df['æ”¶ç›˜ä»·'] = display_df['close']
            if 'high' in display_df.columns:
                display_df['æœ€é«˜'] = display_df['high']
            if 'low' in display_df.columns:
                display_df['æœ€ä½'] = display_df['low']
            if 'volume' in display_df.columns:
                display_df['æˆäº¤é‡'] = display_df['volume']
            if 'sentiment_index' in display_df.columns:
                display_df['æƒ…ç»ªæŒ‡æ•°'] = display_df['sentiment_index']
            if 'signal' in display_df.columns:
                display_df['èƒŒç¦»ä¿¡å·'] = display_df['signal']
            
            display_columns = []
            for col in ['æ—¥æœŸ', 'å¼€ç›˜', 'æ”¶ç›˜ä»·', 'æœ€é«˜', 'æœ€ä½', 'æˆäº¤é‡', 'æƒ…ç»ªæŒ‡æ•°', 'èƒŒç¦»ä¿¡å·']:
                if col in display_df.columns:
                    display_columns.append(col)
            
            st.dataframe(
                display_df[display_columns], 
                width='stretch'
            )
            
            st.subheader("èˆ†æƒ…å¾—åˆ†åˆ†å¸ƒ")
            
            if 'sentiment_index' in combined_df.columns:
                fig_dist = px.histogram(
                    combined_df, 
                    x='sentiment_index', 
                    nbins=30, 
                    marginal="box",
                    title="æƒ…ç»ªæŒ‡æ•°åˆ†å¸ƒ"
                )
                fig_dist.update_layout(height=400)
                st.plotly_chart(fig_dist, width='stretch')
            else:
                st.warning("æƒ…ç»ªæŒ‡æ•°åˆ—ä¸å­˜åœ¨ï¼Œæ— æ³•æ˜¾ç¤ºåˆ†å¸ƒå›¾")
            
            st.subheader("æ•°æ®å¯¼å‡º")
            csv_data = combined_df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="ä¸‹è½½æ•°æ®ä¸ºCSV",
                data=csv_data,
                file_name=f"{stock_code}_analysis_{start_date_str}_{end_date_str}.csv",
                mime="text/csv"
            )
        else:
            st.warning("æ— æ³•è·å–è‚¡ç¥¨æ•°æ®ï¼Œè¯·æ£€æŸ¥è‚¡ç¥¨ä»£ç å’Œæ—¥æœŸèŒƒå›´")
    except Exception as e:
        st.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")
        st.exception(e)

st.markdown("---")
st.markdown("ğŸ“Š è‚¡ç¥¨æƒ…ç»ªåˆ†æä¸è¶‹åŠ¿æ´å¯Ÿå·¥å…· | æ•°æ®æ¥æºï¼šAkShare | èˆ†æƒ…åˆ†æï¼šFinBERT | æ–°é—»æºï¼šä¸œæ–¹è´¢å¯Œå®˜æ–¹ (AKShare æ¥å£)")
st.markdown("âš ï¸ æ³¨æ„ï¼šæœ¬å·¥å…·ä»…ä¾›å­¦ä¹ ç ”ç©¶ä½¿ç”¨ï¼Œä¸æ„æˆä»»ä½•æŠ•èµ„å»ºè®®")
